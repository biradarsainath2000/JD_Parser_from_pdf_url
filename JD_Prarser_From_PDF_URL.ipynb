{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a smart and interactive Job Description (JD) parser tool built using Gradio and LLMs (LLaMA3 via Groq). It extracts, cleans, and rewrites job descriptions from two types of inputs:\n",
        "\n",
        "1.Using URLs\n",
        "\n",
        "2.Using Single pdf/Multiple pdf"
      ],
      "metadata": {
        "id": "Xi8Ifp6nP-au"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing All Libs"
      ],
      "metadata": {
        "id": "UQbvJ4MIgzR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 gradio PyMuPDF pypdf groq pypdf2"
      ],
      "metadata": {
        "id": "VzxFbOp0cQWf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing** **all libs**"
      ],
      "metadata": {
        "id": "m9j1VYviS5_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os         # Handles operating system environment variables and file paths\n",
        "import re         # Used for regular expressions (text pattern matching and substitution)\n",
        "import unicodedata  # Used for normalizing and cleaning text (e.g., removing accents)\n",
        "import gradio as gr  # Gradio library to build web UI for your JD parser\n",
        "\n",
        "import pymupdf       # Library for extracting text from PDF files (also known as fitz)\n",
        "from pypdf import PdfReader  # Fallback PDF reader in case PyMuPDF fails\n",
        "from groq import Groq  # Groq client to interact with LLaMA3-based models via Groq API\n",
        "\n",
        "import requests            # Used for making HTTP requests (scraping webpages, calling APIs)\n",
        "from bs4 import BeautifulSoup  # For parsing and extracting text from HTML (job pages)\n",
        "import json                # To format and handle JSON data (API payloads, outputs)\n",
        "\n",
        "from google.colab import userdata  # Special Colab module to securely access API keys\n",
        "import zipfile       # Used to compress and bundle multiple files into a ZIP archive\n"
      ],
      "metadata": {
        "id": "zyYA8ulJIK7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 1.To Scrape Job Content From Job Portal URLs."
      ],
      "metadata": {
        "id": "BOPWWotBIj34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PART 1: URL Scraper + JD Extractor ===\n",
        "\n",
        "# Set Groq API Key securely from Colab's userdata (better than hardcoding)\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")   # Secure API key access\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")                    #  Load key from environment\n",
        "GROQ_MODEL = \"llama3-8b-8192\"                               #  Use LLaMA3 8B model for extraction\n",
        "\n",
        "#  Function to scrape any job page URL and extract full body text\n",
        "def scrape_job_page_generic(url):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Spoof browser user-agent\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=15)  # Make HTTP GET request\n",
        "        response.raise_for_status()  # Raise error for bad status codes (4xx, 5xx)\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"Failed to fetch page: {str(e)}\"}  #  Return error if fetch fails\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")  # Parse HTML content\n",
        "    body_text = soup.body.get_text(separator=\"\\n\", strip=True) if soup.body else \"No body text found\"  #  Extract visible text\n",
        "    return {\"content\": body_text}  # Return extracted content in dict\n",
        "\n",
        "#  Use LLaMA3 to clean and extract structured job fields from raw scraped text\n",
        "def clean_with_llama3(raw_data):\n",
        "    prompt = f\"\"\"\n",
        "You are a smart job information extractor.\n",
        "\n",
        "From the below raw text scraped from a job detail page, extract the following fields clearly:\n",
        "- \"Role\"\n",
        "- \"Job Description\"\n",
        "- \"Qualification\"\n",
        "- \"Locations\"\n",
        "- \"Additional Information\"\n",
        "- \"About\"\n",
        "- \"Important Notice\"\n",
        "\n",
        "Output the result in this format (line-by-line):\n",
        "\n",
        "\"Role\": ...\n",
        "\"Job Description\": ...\n",
        "\"Qualification\": ...\n",
        "\"Locations\": ...\n",
        "\"Additional Information\": ...\n",
        "\"About\": ...\n",
        "\"Important Notice\": ...\n",
        "\n",
        "If some data is not available, just write \"Not found\".\n",
        "\n",
        "Raw Scraped Content:\n",
        "{json.dumps(raw_data, indent=2)}\n",
        "    \"\"\"  # 📋 Prompt tells the LLM how to extract clean fields\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",  #  Auth header\n",
        "        \"Content-Type\": \"application/json\"          #  Set content type for JSON API\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"model\": GROQ_MODEL,  #  Use selected LLaMA3 model\n",
        "        \"messages\": [         # Chat-style messages (system + user prompt)\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts job content into labeled fields.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"temperature\": 0.3    # Low temperature for accurate, stable output\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\", headers=headers, json=payload)  #  Send request to Groq LLM\n",
        "        response.raise_for_status()  #  Raise error if API fails\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()  # Return cleaned output\n",
        "    except Exception as e:\n",
        "        return f\"Error during LLM call: {str(e)}\"  #  Return error string if call fails\n",
        "\n",
        "# 🔄 Wrapper function to combine scraping and cleaning steps\n",
        "def extract_job_details_from_url(url):\n",
        "    scraped = scrape_job_page_generic(url)        #  Scrape raw job content\n",
        "    if \"error\" in scraped:                         #  Handle errors in scraping\n",
        "        return scraped[\"error\"]\n",
        "    return clean_with_llama3(scraped)              #  Clean and extract fields\n",
        "\n",
        "# ✅ Example Run\n",
        "print(extract_job_details_from_url(\"https://www.accenture.com/in-en/careers/jobdetails?id=ATCI-4995350-S1864578_en&title=Software+Development+Lead\"))  # 🧪 Test with a real job URL\n"
      ],
      "metadata": {
        "id": "Z8qqaxqRJqFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 2: PDF/TXT Extractor + Cleaner + Rewriter\n"
      ],
      "metadata": {
        "id": "7lxn3mhNL91R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single & Multi-File Handling\n",
        "\n",
        "Single JD Mode: Processes one file and returns extracted, cleaned, and rewritten versions.\n",
        "\n",
        "Multiple JD Mode: Loops over multiple files, rewrites each one, and saves them into a downloadable"
      ],
      "metadata": {
        "id": "C_WmNf1TLthG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Groq client with the API key from environment variables\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "#  Extract text from PDF or TXT file\n",
        "def extract_text_from_path(file_path):\n",
        "    try:\n",
        "        if file_path.endswith('.pdf'):  #  If the uploaded file is a PDF\n",
        "            text = \"\"\n",
        "            with pymupdf.open(file_path) as doc:  # Try reading using PyMuPDF\n",
        "                for page in doc:\n",
        "                    text += page.get_text()  # Collect text from each page\n",
        "            if text.strip():                  #  If text is found, return it\n",
        "                return text.strip()\n",
        "\n",
        "            # Fallback to PyPDF if PyMuPDF failed\n",
        "            reader = PdfReader(file_path)\n",
        "            fallback = \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
        "            return fallback.strip()\n",
        "\n",
        "        elif file_path.endswith('.txt'):               #If the uploaded file is a plain text file\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                return f.read().strip()                #  Read and return text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"                           # Handle any exceptions\n",
        "\n",
        "    return \"Unsupported file\"                           #  If not PDF/TXT\n",
        "\n",
        "#  Clean and normalize extracted text\n",
        "def sanitize_text(text):\n",
        "    clean = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')  #  Remove accents\n",
        "    clean = re.sub(r'\\s+', ' ', clean)        #Collapse all whitespace to single space\n",
        "    return clean.strip()                      # Return cleaned string\n",
        "\n",
        "#  Rewrite the JD using LLM (Groq's LLaMA3)\n",
        "def rewrite_jd_with_llm(jd_text):\n",
        "    prompt = f\"\"\"\n",
        "You are a skilled HR content writer.\n",
        "\n",
        "Your job is to rewrite the JD below:\n",
        "- Professional & clear\n",
        "- ATS-friendly\n",
        "- Structured using markdown (**bold**, *italic*, - bullet points, etc.)\n",
        "\n",
        "--- JD START ---\n",
        "{jd_text}\n",
        "--- JD END ---\n",
        "\n",
        "Rewrite now:\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=GROQ_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]  #  Send prompt to LLM\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()  #  Return the rewritten JD\n",
        "    except Exception as e:\n",
        "        return f\"LLM Error: {e}\"  #  Catch and return any LLM error\n",
        "\n",
        "# Handle a single uploaded JD file\n",
        "def handle_single(file):\n",
        "    if file is None:  #  Check if file is empty\n",
        "        return \"No file\", \"No cleaned\", \"No rewrite\", None\n",
        "\n",
        "    extracted = extract_text_from_path(file.name)     # Extract raw text\n",
        "    cleaned = sanitize_text(extracted)                # Clean the text\n",
        "    rewritten = rewrite_jd_with_llm(cleaned)          #  Rewrite using LLM\n",
        "\n",
        "    out_path = file.name.replace(\".pdf\", \"_rewritten.md\").replace(\".txt\", \"_rewritten.md\")  #  Output path\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:  # Save rewritten JD to file\n",
        "        f.write(rewritten)\n",
        "\n",
        "    return extracted[:1000], cleaned[:1000], rewritten[:1500], out_path  # Return results for display\n",
        "\n",
        "#  Handle multiple uploaded JD files\n",
        "def handle_multiple(files):\n",
        "    results = []  #  List to collect all results\n",
        "    zipf = zipfile.ZipFile(\"All_Rewritten_JDs.zip\", \"w\", zipfile.ZIP_DEFLATED)  # 🗜️ Create zip archive\n",
        "\n",
        "    for file in files:\n",
        "        fname = os.path.basename(file.name)  #  Get filename\n",
        "        raw = extract_text_from_path(file.name)  #  Extract raw text\n",
        "        cleaned = sanitize_text(raw)             #  Clean it\n",
        "        rewritten = rewrite_jd_with_llm(cleaned) #  Rewrite it\n",
        "\n",
        "        rewritten_path = f\"rewritten_{fname}.md\"  #  Output markdown file path\n",
        "        with open(rewritten_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(rewritten)  #  Save rewritten JD\n",
        "\n",
        "        zipf.write(rewritten_path)  #  Add file to zip\n",
        "        results.append((fname, raw[:600], cleaned[:600], rewritten[:1000], rewritten_path))  #  Collect output\n",
        "\n",
        "    zipf.close()  #  Close zip file after writing\n",
        "    return results, \"All_Rewritten_JDs.zip\"  # Return data + zip file path\n"
      ],
      "metadata": {
        "id": "RwDFeokGLrhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Provides a interactive interface for JD processing\n",
        "\n"
      ],
      "metadata": {
        "id": "NdRihXU5QtG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supports multi-file upload, file previews, formatted output, and downloads\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ug3o-G9KRFur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr    # Import Gradio for building the web-based interface\n",
        "\n",
        "# Custom CSS to style the entire app (animations, colors, borders, etc.)\n",
        "\n",
        "custom_css = \"\"\"\n",
        "\n",
        "@keyframes dash-light {\n",
        "  0% {\n",
        "    border-color: #b6d0e2;\n",
        "    box-shadow: 0 0 3px #b6d0e2;\n",
        "  }\n",
        "  50% {\n",
        "    border-color: #ffb6c1;\n",
        "    box-shadow: 0 0 6px #ffb6c1;\n",
        "  }\n",
        "  100% {\n",
        "    border-color: #b6d0e2;\n",
        "    box-shadow: 0 0 3px #b6d0e2;\n",
        "  }\n",
        "}\n",
        "\n",
        "#title-box {\n",
        "    border: 2px dashed #b6d0e2;\n",
        "    border-radius: 4px;\n",
        "    padding: 10px 15px;\n",
        "    background-color: #fff7fb;\n",
        "    text-align: center;\n",
        "    font-weight: 600;\n",
        "    font-size: 18px;\n",
        "    color: #ff1493;  /* Pink text */\n",
        "    margin: 20px auto;\n",
        "    width: 70%;\n",
        "    animation: dash-light 6s infinite ease-in-out;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "/* Optional entire background */\n",
        "body {\n",
        "    background-color: #b6d0e2 !important;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "@keyframes animatedGradient {\n",
        "    0% { background-position: 0% 50%; }\n",
        "    50% { background-position: 100% 50%; }\n",
        "    100% { background-position: 0% 50%; }\n",
        "}\n",
        "body {\n",
        "    background: linear-gradient(-45deg, #f8e1ff, #fdf4ff, #ffe6f0, #f3f0ff);\n",
        "    background-size: 400% 400%;\n",
        "    animation: animatedGradient 15s ease infinite;\n",
        "}\n",
        "h1, h2, h3, .prose h2 {\n",
        "    color: #ff69b4;\n",
        "    font-weight: bold;\n",
        "    text-align: center;\n",
        "    animation: fadeIn 1s ease;\n",
        "}\n",
        "/* Purple Tab Borders Only */\n",
        "button[role=\"tab\"] {\n",
        "    background-color: transparent; /* No background fill */\n",
        "    color: #22c55e;               /* Optional: Text matches border */\n",
        "    border: 2px solid #22c55e;    /* Border in purple */\n",
        "    font-weight: bold;\n",
        "    border-radius: 10px;\n",
        "    margin: 5px;\n",
        "    padding: 6px 12px;            /* Optional: Adds some space inside button */\n",
        "}\n",
        "button[role=\"tab\"]:hover {\n",
        "    transform: scale(1.05);\n",
        "}\n",
        "button.process-btn {\n",
        "    background-color: #3b82f6;\n",
        "    color: white;\n",
        "    font-weight: bold;\n",
        "    border-radius: 10px;\n",
        "    padding: 10px 20px;\n",
        "    transition: all 0.3s ease-in-out;\n",
        "}\n",
        "button.process-btn:hover {\n",
        "    background-color: #4ade80;\n",
        "    box-shadow: 0 0 10px #4ade80;\n",
        "    transform: scale(1.05);\n",
        "}\n",
        ".upload-box {\n",
        "    border: 2px solid #8a2be2;\n",
        "    border-radius: 12px;\n",
        "    padding: 15px;\n",
        "    background-color: #f9f7ff;\n",
        "    margin-bottom: 15px;\n",
        "    transition: box-shadow 0.3s ease;\n",
        "}\n",
        ".upload-box:hover {\n",
        "    box-shadow: 0 0 15px #a78bfa;\n",
        "}\n",
        "\n",
        "/* ✅ GREEN LABELS ONLY for Single JD tab */\n",
        ".single-jd label, .single-jd span {\n",
        "    color: #22c55e !important;\n",
        "    font-weight: bold;\n",
        "}\n",
        "\n",
        "/* Don't touch Multiple JD tab */\n",
        "textarea, .gr-textbox {\n",
        "    border: 2px solid #8a2be2 !important;\n",
        "    border-radius: 12px;\n",
        "    background-color: #fdfdff;\n",
        "}\n",
        "footer, #footer {\n",
        "    background-color: #ffe6f0;\n",
        "    color: #ff1493;\n",
        "    font-weight: bold;\n",
        "    text-align: center;\n",
        "    border-radius: 12px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the Gradio app layout using Blocks\n",
        "\n",
        "with gr.Blocks(css=custom_css) as app:\n",
        "    with gr.Column(elem_classes=[\"app-border\"]):# Main column wrapper\n",
        "        gr.HTML('<div id=\"title-box\">JD PARSER FROM PDFS </div>')\n",
        "\n",
        "        with gr.Tabs(): # Create tabs for single and multiple JD parsing\n",
        "            ...\n",
        "            # Tab for single JD processing\n",
        "            with gr.Tab(\"📄 Single JD\"):\n",
        "                with gr.Column(elem_classes=[\"upload-box\", \"single-jd\"]):\n",
        "                    file_in = gr.File(label=\"Upload JD\", file_types=[\".pdf\", \".txt\"])\n",
        "                    go_btn = gr.Button(\"✨ Process JD\", elem_classes=[\"process-btn\"])\n",
        "\n",
        "                with gr.Column(elem_classes=[\"single-jd\"]):\n",
        "                    raw = gr.Textbox(label=\"Raw Extracted\", lines=6, elem_id=\"raw\")# Display raw extracted text\n",
        "                clean = gr.Textbox(label=\"Cleaned\", lines=6, elem_id=\"clean\")# Display cleaned text\n",
        "                final = gr.Textbox(label=\" Rewritten JD\", lines=10, elem_id=\"final\")# Display rewritten JD\n",
        "\n",
        "\n",
        "                download = gr.File(label=\"⬇ Download Final JD\")\n",
        "\n",
        "                go_btn.click(handle_single, inputs=file_in, outputs=[raw, clean, final, download])\n",
        "\n",
        "            # ✅ MULTIPLE JD SECTION - DEFAULT BLACK\n",
        "            with gr.Tab(\"📁 Multiple JDs\"):\n",
        "                with gr.Column(elem_classes=[\"upload-box\"]):\n",
        "                    multi_in = gr.File(label=\"Upload JDs\", file_types=[\".pdf\", \".txt\"], file_count=\"multiple\")# Upload multiple JDs\n",
        "                    multi_btn = gr.Button(\"Process All JDs\", elem_classes=[\"process-btn\"])\n",
        "\n",
        "                output_df = gr.Dataframe(headers=[\"File\", \"Raw\", \"Cleaned\", \"Rewritten\", \"Download\"], wrap=True)\n",
        "                zip_download = gr.File(label=\"⬇ Download All in ZIP\")\n",
        "\n",
        "                def run_multi(files):  # Process each file and return results\n",
        "                    data, zipfile_path = handle_multiple(files)\n",
        "                    return [[d[0], d[1], d[2], d[3], d[4]] for d in data], zipfile_path\n",
        "\n",
        "                multi_btn.click(run_multi, inputs=multi_in, outputs=[output_df, zip_download])\n",
        "\n",
        "\n",
        "# ✅ Launch app\n",
        "app.launch()\n"
      ],
      "metadata": {
        "id": "216mV7elODXi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}